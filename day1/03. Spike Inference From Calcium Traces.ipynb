{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cd9031ed",
      "metadata": {
        "id": "cd9031ed",
        "outputId": "47b08667-fddc-4a5a-8320-3233d6910bb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting oasis-deconv\n",
            "  Downloading oasis_deconv-0.2.1.tar.gz (285 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.0/286.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from oasis-deconv) (3.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Building wheels for collected packages: oasis-deconv\n",
            "  Building wheel for oasis-deconv (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oasis-deconv: filename=oasis_deconv-0.2.1-cp311-cp311-linux_x86_64.whl size=1361549 sha256=f1b775de5e0f80f51d1781d4033cf3b75b7fb2188dfc65e761f78478ab4ad275\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/9e/1d/099cbf6b77b55f4cac20b600c4fa6385f6dc65a75d755159f2\n",
            "Successfully built oasis-deconv\n",
            "Installing collected packages: oasis-deconv\n",
            "Successfully installed oasis-deconv-0.2.1\n"
          ]
        }
      ],
      "source": [
        "%pip install numpy scipy matplotlib oasis-deconv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "96fa4b6e",
      "metadata": {
        "id": "96fa4b6e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.signal import convolve, windows\n",
        "import matplotlib.pyplot as plt\n",
        "from oasis.functions import deconvolve, gen_data\n",
        "from scipy.signal import find_peaks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7b03c242",
      "metadata": {
        "id": "7b03c242"
      },
      "outputs": [],
      "source": [
        "y1, c1, s1 = map(np.squeeze, gen_data(N=1, seed=5, sn=0.1, framerate=10))\n",
        "y2, c2, s2 = map(np.squeeze, gen_data(N=1, seed=5, sn=0.1, framerate=20))\n",
        "y3, c3, s3 = map(np.squeeze, gen_data(N=1, seed=5, sn=0.1, framerate=30))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8576ad2",
      "metadata": {
        "id": "d8576ad2"
      },
      "source": [
        "# Spike Inference From Calcium Traces\n",
        "\n",
        "To extract spikes from calcium traces, it is essential to understand how calcium signals are generated from neural activity. Neurons fire rapidly, but calcium signals reflect this activity as slower, smoother traces. Convolution describes how spikes are transformed into calcium signals. To recover the original spikes, we use methods like OASIS to deconvolve the calcium traces. The output is continuous, so we apply thresholding to identify discrete spike events. Finally, these spike events are timestamped for further analysis and comparison.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c30342ee",
      "metadata": {
        "id": "c30342ee"
      },
      "source": [
        "## How would a spike train appear as a calcium trace? (Convolution)\n",
        "\n",
        "In this section, we will see how calcium signals are produced from spikes using a process called convolution. When a neuron fires, it does not just cause a sharp, brief change in the signal. Instead, it produces a smooth, slowly fading signal that we observe in calcium imaging. We simulate this by convolving a spike train with a calcium kernel which a shape that describes how the signal should look after a single spike. This helps us understand how fast spiking activity is transformed into the slower calcium traces we record.\n",
        "\n",
        "| **Code**                                         | **Description**                                                                                    |\n",
        "| :----------------------------------------------- | :------------------------------------------------------------------------------------------------- |\n",
        "| `windows.boxcar(win_len)`                        | Create a **boxcar kernel** of specified length (`win_len`).                                        |\n",
        "| `windows.triang(win_len)`                        | Create a **triangle kernel** of specified length (`win_len`).                                      |\n",
        "| `np.exp(-t / tau)`                               | Create an **exponential decay kernel** with decay constant `tau`.                                  |\n",
        "| `np.exp(-t / tau_decay) - np.exp(-t / tau_rise)` | Create a **double exponential decay kernel** with rise (`tau_rise`) and decay (`tau_decay`) times. |\n",
        "| `kernel_unnorm / kernel_unnorm.sum()`            | Normalize the kernel by dividing by the sum of its elements.                                       |\n",
        "| `convolve(s1, kernel, mode='full')`              | **Convolve** the spike train (`s1`) with the kernel, generating a calcium trace.                   |\n",
        "| `plt.plot(kernel)`                                     | Plot the kernel.   |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f415cd5",
      "metadata": {
        "id": "6f415cd5"
      },
      "source": [
        "*How will my spikes look if they are convolved with a prebuilt kernel?*\n",
        "\n",
        "**Example** How will my spikes look if they were convolved with a boxcar kernel of window size 3?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff2d11ae",
      "metadata": {
        "id": "ff2d11ae"
      },
      "outputs": [],
      "source": [
        "win_len = 3\n",
        "kernel_unnorm = windows.boxcar(win_len)\n",
        "kernel = kernel_unnorm / kernel_unnorm.sum()\n",
        "convolved_trace = convolve(s1, kernel, mode='full')\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.plot(kernel)\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.plot(s1)\n",
        "plt.plot(convolved_trace[:-win_len+1], color='r')\n",
        "plt.xlim(0, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "673d1c0f",
      "metadata": {
        "id": "673d1c0f"
      },
      "source": [
        "How will my spikes look if they were convolved with a triangle kernel of window size 3?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dff2c44",
      "metadata": {
        "id": "9dff2c44"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a141628b",
      "metadata": {
        "id": "a141628b"
      },
      "source": [
        "How will my spikes look if they were convolved with a triangle kernel of window size 4?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7ecee11",
      "metadata": {
        "id": "e7ecee11"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b5c35c66",
      "metadata": {
        "id": "b5c35c66"
      },
      "source": [
        "*How will my spikes look if they are convolved with an exponential decay kernel?*\n",
        "\n",
        "**Example** How will my spikes look when convolved with an exponential decay kernel with tau of 10 and window size of 101 frames?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab7967bb",
      "metadata": {
        "id": "ab7967bb"
      },
      "outputs": [],
      "source": [
        "tau = 10\n",
        "win_len = 101\n",
        "t = np.arange(win_len)\n",
        "kernel_unnorm = np.exp(-t / tau)\n",
        "kernel = kernel_unnorm / kernel_unnorm.sum()\n",
        "convolved_trace = convolve(s1, kernel, mode='full')\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.plot(kernel)\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.plot(s1)\n",
        "plt.plot(convolved_trace[:-win_len+1], color='r')\n",
        "plt.xlim(0, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00f5bcc0",
      "metadata": {
        "id": "00f5bcc0"
      },
      "source": [
        "How will my spikes look when convolved with an exponential decay kernel with tau of 1 frames and window size of 101 frames?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76965d0b",
      "metadata": {
        "id": "76965d0b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2b47ce58",
      "metadata": {
        "id": "2b47ce58"
      },
      "source": [
        "How will my spikes look when convolved with an exponential decay kernel with tau of 200 frames and window size of 101 frames?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9133355b",
      "metadata": {
        "id": "9133355b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d66f1e9a",
      "metadata": {
        "id": "d66f1e9a"
      },
      "source": [
        "*How will my spikes look if they are convolved with a double exponential decay kernel?*\n",
        "\n",
        "**Example** How will my spikes look when convolved with a double exponential decay kernel with tau rise of 0.1 frame, tau_decay of 1.5 frames, and window size of 101 frames?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c66a0fb9",
      "metadata": {
        "id": "c66a0fb9"
      },
      "outputs": [],
      "source": [
        "tau_rise = 0.1\n",
        "tau_decay = 1.5\n",
        "win_len = 101\n",
        "t = np.arange(win_len)\n",
        "kernel_unnorm = np.exp(-t / tau_decay) - np.exp(-t / tau_rise)\n",
        "kernel = kernel_unnorm / kernel_unnorm.sum()\n",
        "convolved_trace = convolve(s1, kernel, mode='full')\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.plot(kernel)\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.plot(s1)\n",
        "plt.plot(convolved_trace[:-win_len+1], color='r')\n",
        "plt.xlim(0, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cfedc58",
      "metadata": {
        "id": "7cfedc58"
      },
      "source": [
        "How will my spikes look when convolved with a double exponential decay kernel with tau rise of 29.9 frame, tau_decay of 30.0 frames, and window size of 101 frames?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56ddbf5c",
      "metadata": {
        "id": "56ddbf5c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c9a8f727",
      "metadata": {
        "id": "c9a8f727"
      },
      "source": [
        "How will my spikes look when convolved with a double exponential decay kernel with tau rise of 0.1 frame, tau_decay of 4.0 frames, and window size of 101 frames?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f79478d",
      "metadata": {
        "id": "9f79478d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "52761600",
      "metadata": {
        "id": "52761600"
      },
      "source": [
        "## OASIS\n",
        "\n",
        "Now that we know how spikes generate calcium signals using a kernel, we want to do the reverse: go from calcium traces back to the original spikes. This is done through deconvolution. OASIS is a commonly used algorithm that estimates spike timings by finding a sparse set of events that, when convolved with a known calcium kernel, best matches the observed signal. The output is a continuous signal where higher values suggest stronger or more likely spike events.\n",
        "\n",
        "| **Code**                        | **Description**                                                                                                 |\n",
        "| :------------------------------ | :-------------------------------------------------------------------------------------------------------------- |\n",
        "| `plt.subplot(211)`              | Set up the first subplot for plotting.                                                                          |\n",
        "| `plt.subplot(212)`              | Set up the second subplot for plotting.                                                                         |\n",
        "| `deconvolve(y)`                 | Apply the **deconvolution** function to the calcium trace `y` to infer spikes and baseline.                     |\n",
        "| `plt.axhline(baseline)`         | Plot a horizontal line at the estimated **baseline** value.                                                     |\n",
        "| `deconvolve(y, g=(0.9,))`       | Apply **deconvolution** to the calcium trace `y` with the parameter `g=(0.9,)` to modify spike inference.       |\n",
        "| `deconvolve(y, g=(1.8, -0.81))` | Apply **deconvolution** to the calcium trace `y` with the parameter `g=(1.8, -0.81)` to modify spike inference. |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "646069fa",
      "metadata": {
        "id": "646069fa"
      },
      "source": [
        "*I have calcium trace from a neuron. How can I infer spikes from it?*\n",
        "\n",
        "**Example** Estimate spikes from calcium trace `y1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c4ac4ee",
      "metadata": {
        "id": "3c4ac4ee"
      },
      "outputs": [],
      "source": [
        "inferred_trace, estimated_spikes, estimated_baseline, g, _ = deconvolve(y1)\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.plot(y1)\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.plot(estimated_spikes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cea6c46",
      "metadata": {
        "id": "1cea6c46"
      },
      "source": [
        "Estimate spikes from calcium trace `y2` and also plot the estimated baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3fb7f29",
      "metadata": {
        "id": "f3fb7f29"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2c57a8f0",
      "metadata": {
        "id": "2c57a8f0"
      },
      "source": [
        "Estimate spikes from calcium trace `y3` and also add estimated baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42628679",
      "metadata": {
        "id": "42628679"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "821c4fc7",
      "metadata": {
        "id": "821c4fc7"
      },
      "source": [
        "*How can I control for fast and slow decay of calcium transients?*\n",
        "\n",
        "**Example** Give g1 co-efficient as 0.9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "029b65e9",
      "metadata": {
        "id": "029b65e9"
      },
      "outputs": [],
      "source": [
        "inferred_trace, estimated_spikes, estimated_baseline, g, _ = deconvolve(y3, g=(0.9,))\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.plot(y3)\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.plot(estimated_spikes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dd78ea5",
      "metadata": {
        "id": "3dd78ea5"
      },
      "source": [
        "Give g1 co-efficient as 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26d1c8e2",
      "metadata": {
        "id": "26d1c8e2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f3a55785",
      "metadata": {
        "id": "f3a55785"
      },
      "source": [
        "Give g1 co-efficient as 0.99."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6979f61c",
      "metadata": {
        "id": "6979f61c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "bfdb6b0e",
      "metadata": {
        "id": "bfdb6b0e"
      },
      "source": [
        "Give g1 co-efficient as 0.9 and g2 as -0.81."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dca4924",
      "metadata": {
        "id": "9dca4924"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0e9dba00",
      "metadata": {
        "id": "0e9dba00"
      },
      "source": [
        "*How can I compare the trace inferred from the spikes with my real calcium signal?*\n",
        "\n",
        "**Example** Compare the inferred calcium traces with real calcium trace of y1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316b259d",
      "metadata": {
        "id": "316b259d"
      },
      "outputs": [],
      "source": [
        "inferred_trace, estimated_spikes, estimated_baseline, g, _ = deconvolve(y1)\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.plot(y1)\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.plot(inferred_trace)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec5f9358",
      "metadata": {
        "id": "ec5f9358"
      },
      "source": [
        "Compare the inferred calcium traces with real calcium trace of y2 with g1 as 0.9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32282090",
      "metadata": {
        "id": "32282090"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f3ff8bf4",
      "metadata": {
        "id": "f3ff8bf4"
      },
      "source": [
        "Compare the inferred calcium traces with real calcium trace of y1 with g1 as 1.8 and g2 as -0.81."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ddcf206",
      "metadata": {
        "id": "8ddcf206"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "58417f44",
      "metadata": {
        "id": "58417f44"
      },
      "source": [
        "## Thresholding and Spike times\n",
        "\n",
        "The output from OASIS is continuous, showing how likely or strong each spike might be. But for many kinds of analysis, we need clear events where either a spike happened, or it did not. To do this, we apply a threshold to the OASIS output. Any value above the threshold is considered a spike.\n",
        "\n",
        "| **Code**                                     | **Description**                                                |\n",
        "| :------------------------------------------- | :------------------------------------------------------------- |\n",
        "| `np.max(spikes)`                             | Get the **maximum** spike value.                               |\n",
        "| `np.percentile(spikes, 95)`                  | Find the **95th percentile** of spikes.                        |\n",
        "| `np.mean(spikes)`                            | Calculate the **mean** of spikes.                              |\n",
        "| `np.std(spikes)`                             | Compute the **standard deviation** of spikes.                  |\n",
        "| `fr = 10`                                    | Set **sampling frequency** to 10 Hz.                           |\n",
        "| `spk_inds = np.where(spikes > threshold)[0]` | Identify **spike indices** above threshold.                    |\n",
        "| `spk_times = spk_inds / fr`                  | Convert **spike indices** to **times**.                        |\n",
        "| `plt.eventplot(spk_times)`                   | Plot **spike times** as events.                                |\n",
        "| `find_peaks(spikes, height=0.5, distance=5)` | **Detect peaks** in spikes with height > 0.5 and distance > 5. |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49db2954",
      "metadata": {
        "id": "49db2954"
      },
      "outputs": [],
      "source": [
        "_, inferred_spikes1, _, _, _ = deconvolve(y1)\n",
        "_, inferred_spikes2, _, _, _ = deconvolve(y2)\n",
        "_, inferred_spikes3, _, _, _ = deconvolve(y3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d592183",
      "metadata": {
        "id": "5d592183"
      },
      "source": [
        "*How do I get spike times by fixing an amplitude manually?*\n",
        "\n",
        "**Example** For y1, find spike times of all spikes with amplitude larger than 1.0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5218ba2",
      "metadata": {
        "id": "f5218ba2"
      },
      "outputs": [],
      "source": [
        "threshold = 1.0\n",
        "fr = 10\n",
        "spk_inds = np.where(inferred_spikes1 > threshold)[0]\n",
        "spk_times = spk_inds / fr\n",
        "plt.eventplot(spk_times)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd987e61",
      "metadata": {
        "id": "bd987e61"
      },
      "source": [
        "For y1, find spike times of all spikes with amplitude larger than 0.01."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b8f6f79",
      "metadata": {
        "id": "4b8f6f79"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d2788c70",
      "metadata": {
        "id": "d2788c70"
      },
      "source": [
        "For y1, find spike times of all spikes with amplitude larger than 0.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ce4737d",
      "metadata": {
        "id": "6ce4737d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ac7ceda3",
      "metadata": {
        "id": "ac7ceda3"
      },
      "source": [
        "*How can I fix the amplitude threshold automatically?*\n",
        "\n",
        "**Example** For y1, set threshold to be higher than 10% of maximum amplitude."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ca6f2c0",
      "metadata": {
        "id": "4ca6f2c0"
      },
      "outputs": [],
      "source": [
        "threshold = 0.1 * np.max(inferred_spikes1)\n",
        "fr = 10\n",
        "spk_inds = np.where(inferred_spikes1 > threshold)[0]\n",
        "spk_times = spk_inds / fr\n",
        "plt.eventplot(spk_times)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7a4a213",
      "metadata": {
        "id": "d7a4a213"
      },
      "source": [
        "For y1, set threshold to be higher than 95th-percentile of the amplitudes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5da71228",
      "metadata": {
        "id": "5da71228"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9f2f432e",
      "metadata": {
        "id": "9f2f432e"
      },
      "source": [
        "For y1, set threshold to be higher than three-sigma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3384d0",
      "metadata": {
        "id": "dd3384d0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "706a5b89",
      "metadata": {
        "id": "706a5b89"
      },
      "source": [
        "*How can I prevent multiple spike detections from a single calcium event?*\n",
        "\n",
        "**Example** For y1, only get spike times for spikes with amplitudes larger than 0.5 with minimum distance of at least 5 frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68fdc200",
      "metadata": {
        "id": "68fdc200"
      },
      "outputs": [],
      "source": [
        "spk_inds, properties = find_peaks(inferred_spikes1, height=0.5, distance=5)\n",
        "fr = 10\n",
        "spk_times = spk_inds / fr\n",
        "plt.eventplot(spk_times)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "910b9528",
      "metadata": {
        "id": "910b9528"
      },
      "source": [
        "For y1, only get spike times for spikes with amplitudes larger than 0.5 with minimum distance of at least 100 frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55ff4bac",
      "metadata": {
        "id": "55ff4bac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "83d7a6d8",
      "metadata": {
        "id": "83d7a6d8"
      },
      "source": [
        "For y1, only get spike times for spikes with amplitudes larger than 0.5 with minimum distance of at least 10 frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07e15543",
      "metadata": {
        "id": "07e15543"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a1fa942c",
      "metadata": {
        "id": "a1fa942c"
      },
      "source": [
        "## Saving Timestamped Data\n",
        "\n",
        "Once we have identified when spikes likely occurred by thresholding, we save the corresponding time points. These timestamped events are useful for further analysis, such as comparing activity across cells, aligning activity to behavioral events, or building summary statistics. In this section, we will save these spike times as an array of indices or timestamps.\n",
        "\n",
        "| **Code**                                                  | **Description**                                               |\n",
        "| :-------------------------------------------------------- | :------------------------------------------------------------ |\n",
        "| `np.save('spks1.npy', spk_times1)`                        | Save **spike times** for neuron 1 to a `.npy` file.           |\n",
        "| `spk1 = np.load('spks1.npy')`                             | Load **spike times** for neuron 1 from a `.npy` file.         |\n",
        "| `plt.eventplot(spk2)`                                     | Plot **spike times** for neuron 2 as an event plot.           |\n",
        "| `spks = np.array([spk_times1, spk_times2], dtype=object)` | Create an array of **spike times** for multiple neurons.      |\n",
        "| `spks = np.load('spks_1_2.npy', allow_pickle=True)`       | Load **spike times** for multiple neurons from a `.npy` file. |\n",
        "| `plt.eventplot(spks[1])`                                  | Plot **spike times** for neuron 2 from the loaded data.       |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d70980ae",
      "metadata": {
        "id": "d70980ae"
      },
      "outputs": [],
      "source": [
        "threshold = np.percentile(inferred_spikes1, 95)\n",
        "fr = 10\n",
        "spk_inds = np.where(inferred_spikes1 > threshold)[0]\n",
        "spk_times1 = spk_inds / fr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0cbb4f9",
      "metadata": {
        "id": "b0cbb4f9"
      },
      "outputs": [],
      "source": [
        "threshold = np.percentile(inferred_spikes2, 95)\n",
        "fr = 20\n",
        "spk_inds = np.where(inferred_spikes2 > threshold)[0]\n",
        "spk_times2 = spk_inds / fr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5f1093e",
      "metadata": {
        "id": "b5f1093e"
      },
      "outputs": [],
      "source": [
        "threshold = np.percentile(inferred_spikes3, 95)\n",
        "fr = 30\n",
        "spk_inds = np.where(inferred_spikes3 > threshold)[0]\n",
        "spk_times3 = spk_inds / fr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72f77740",
      "metadata": {
        "id": "72f77740"
      },
      "source": [
        "*How do I save spike times of a single neuron?*\n",
        "\n",
        "**Example** Save `spk_times1` as `spk1.npy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2206e90",
      "metadata": {
        "id": "e2206e90"
      },
      "outputs": [],
      "source": [
        "np.save('spk1.npy', spk_times1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0100b3f2",
      "metadata": {
        "id": "0100b3f2"
      },
      "source": [
        "Save `spk_times2` as `spk2.npy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4be129d",
      "metadata": {
        "id": "e4be129d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "35796698",
      "metadata": {
        "id": "35796698"
      },
      "source": [
        "Save `spk_times3` as `spk3.npy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76a13de3",
      "metadata": {
        "id": "76a13de3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0e6347e7",
      "metadata": {
        "id": "0e6347e7"
      },
      "source": [
        "*How do I load spike times of a single neuron?*\n",
        "\n",
        "*Example* Load `spk1.npy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f622ec24",
      "metadata": {
        "id": "f622ec24"
      },
      "outputs": [],
      "source": [
        "spk1 = np.load('spk1.npy')\n",
        "plt.eventplot(spk1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bad3faa",
      "metadata": {
        "id": "0bad3faa"
      },
      "source": [
        "Load `spk2.npy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a1bd1d1",
      "metadata": {
        "id": "9a1bd1d1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "29a92ace",
      "metadata": {
        "id": "29a92ace"
      },
      "source": [
        "Load `spk3.npy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "208c7dd0",
      "metadata": {
        "id": "208c7dd0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2685f3c4",
      "metadata": {
        "id": "2685f3c4"
      },
      "source": [
        "*How do I save spike times of multiple neurons?*\n",
        "\n",
        "**Example** Save `spk_times1` and `spk_times1` together as `spk_1_2.npy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de0cd27f",
      "metadata": {
        "id": "de0cd27f"
      },
      "outputs": [],
      "source": [
        "spks = np.array([spk_times1, spk_times2], dtype=object)\n",
        "np.save('spk_1_2.npy', spks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc8cb407",
      "metadata": {
        "id": "dc8cb407"
      },
      "source": [
        "Save `spk_times2` and `spk_times3` together as `spk_2_3.npy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "521eafd6",
      "metadata": {
        "id": "521eafd6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e885c7a8",
      "metadata": {
        "id": "e885c7a8"
      },
      "source": [
        "Save `spk_times1`, `spk_times2`, and `spk_times3` together as `spk_1_2_3.npy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c33b95",
      "metadata": {
        "id": "d9c33b95"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e35f6277",
      "metadata": {
        "id": "e35f6277"
      },
      "source": [
        "*How do I load spike times of multiple neurons?*\n",
        "\n",
        "**Example** Load `spk_1_2.npy` and plot the events from first neuron."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07cf7846",
      "metadata": {
        "id": "07cf7846"
      },
      "outputs": [],
      "source": [
        "spks = np.load('spk_1_2.npy', allow_pickle=True)\n",
        "plt.eventplot(spks[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea75eece",
      "metadata": {
        "id": "ea75eece"
      },
      "source": [
        "Load `spk_1_2.npy` and plot the events from second neuron."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f88a26c1",
      "metadata": {
        "id": "f88a26c1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5a7f77d1",
      "metadata": {
        "id": "5a7f77d1"
      },
      "source": [
        "Load `spk.npy` and plot the events from the last neuron."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f4e3926",
      "metadata": {
        "id": "8f4e3926"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "calim",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}